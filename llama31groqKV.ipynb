{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzHpyERJJpfVaQszX3bvxy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkrisvasan/llamaKV/blob/main/llama31groqKV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4C1ZmA4RXsa",
        "outputId": "f7a5bd86-b912-45af-d70b-797c4a831931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#https://console.groq.com/keys - register and get GROQ_API_KEY key\n",
        "#https://console.groq.com/docs/libraries - Groq documentation\n",
        "#Open Google Colab, and go to Secrets.\n",
        "#Press \"+ Add new secret\" . Enter the Name HF_TOKEN and Value of the secret.\n",
        "#Once entered Name cannot be changed.\n",
        "#Toggle Notebook access.\n",
        "#Finally, for using it in the notebook, use the given code with the name HF_TOKEN\n",
        "\n",
        "!pip install groq -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq"
      ],
      "metadata": {
        "id": "Y9ucd42hSXRU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "credential_names = [\"GROQ_API_KEY\"]\n",
        "for credential in credential_names:\n",
        "  if credential not in os.environ:\n",
        "    os.environ[credential]=getpass.getpass(\"Provide your...\" + credential)"
      ],
      "metadata": {
        "id": "r2zNUi9HSyrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c8a9ac-b0eb-49a4-efc1-79182928592e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide your...GROQ_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq()"
      ],
      "metadata": {
        "id": "JKsMoLCySiXC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_instruction = \"You are a helpful assistant who gets the youtube video title as prompt and helps to build five question and answer - difficulty level is medium to high\"\n",
        "systemInstruction = input(\"Enter the system Instruction to be provided to the model : \") or default_instruction\n",
        "print(\"System Instruction : \", systemInstruction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO_r_Uqhzz9M",
        "outputId": "7a8e5b87-4d7e-4a94-8868-852633976b2c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the system Instruction to be provided to the model : \n",
            "System Instruction :  You are a helpful assistant who gets the youtube video title as prompt and helps to build five question and answer - difficulty level is medium to high\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_content(prompt,conversation_history=[]):\n",
        "  # Append the current prompt to the conversation history\n",
        "  conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": systemInstruction},\n",
        "      *conversation_history  # Include the conversation history\n",
        "    ]\n",
        "  )\n",
        "  # Extract the chatbot's response and append it to the history\n",
        "  chatbot_response = response.choices[0].message.content\n",
        "  conversation_history.append({\"role\": \"assistant\", \"content\": chatbot_response})\n",
        "\n",
        "  return chatbot_response"
      ],
      "metadata": {
        "id": "9qTIA56mTT9G"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the chatbot interaction loop\n",
        "conversation_history = []\n",
        "defaultUserPrompt = \"Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast\"\n",
        "userPrompt = input(\"Enter the first user prompt to the model : \") or defaultUserPrompt\n",
        "print(\"User Prompt : \",userPrompt)\n",
        "output = generate_content(userPrompt,conversation_history)\n",
        "print(output)\n",
        "\n",
        "while True:\n",
        "  user_input = input(\"\\n\\n**You: ** [type 'exit' to close chat]\")\n",
        "  if user_input.lower() == \"exit\":\n",
        "    break\n",
        "  response = generate_content(user_input,conversation_history)\n",
        "  print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s98L3Bi1Jws",
        "outputId": "7a70b518-8517-4abc-98dd-bb8765b0945a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the first user prompt to the model : \n",
            "User Prompt :  Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast\n",
            "Here are five questions and answers (Q&A) based on the podcast 'Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast':\n",
            "\n",
            "**Q1:** What is the primary goal of Neuralink, as stated by Elon Musk in the podcast?\n",
            "**A1:** According to Elon Musk, the primary goal of Neuralink is to develop a high-bandwidth interface between the human brain and a computer, enabling humans to ultimately achieve a symbiosis with artificial intelligence, thereby avoiding the risks of AI surpassing human intelligence.\n",
            "\n",
            "**Q2:** What is the significance of the Brain-Machine Interface (BMI) for the treatment of medical conditions such as paralysis, as discussed in the podcast?\n",
            "**A2:** The BMI developed by Neuralink has the potential to restore motor function in individuals suffering from paralysis, stroke, or other neurological disorders by reconnecting damaged neurons and allowing people to control devices with their thoughts.\n",
            "\n",
            "**Q3:** In the context of the podcast, what is the difference between 'full-uploading' and 'editing' the human brain, according to Elon Musk?\n",
            "**A3:** Elon Musk mentioned that 'full-uploading' refers to completely uploading a human brain into a digital environment, essentially allowing the person to live on in a virtual form. On the other hand, 'editing' the brain involves enhancing cognitive abilities, memory, or other functions, without fully transferring the individual into a digital form.\n",
            "\n",
            "**Q4:** What advancements in neural implants and technology have allowed Neuralink to develop smaller, more advanced implants that could be integrated into the human brain?\n",
            "**A4:** According to Elon Musk, advancements in areas such as nanotechnology, neural cell implantation, and rapid manufacturing have enabled Neuralink to develop smaller, more advanced implants that could potentially integrate seamlessly into the human brain.\n",
            "\n",
            "**Q5:** In the podcast, how does Elon Musk view the future of humanity in relation to the development of advanced artificial intelligence and neural interfaces?\n",
            "**A5:** Elon Musk expresses concerns about the potential dangers of advanced AI, particularly if humans are unable to keep pace with its development. However, he believes that the development of neural interfaces like Neuralink could provide a safeguard against this risk by enabling humans to effectively coexist and integrate with AI.\n",
            "\n",
            "\n",
            "**You: ** [type 'exit' to close chat]creative use case for learning and talent development industry based on video disvussion\n",
            "Chatbot: Based on the podcast 'Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast', here are some creative use cases for the learning and talent development industry:\n",
            "\n",
            "**1. Brain-Computer Interface (BCI) Training Platforms**\n",
            "\n",
            "Develop BCI training platforms that leverage Neuralink-like technologies to help learners acquire new skills more efficiently. Learners could use brain-computer interfaces to enhance their cognitive abilities, improve focus, and boost memory retention.\n",
            "\n",
            "**2. Predictive Learning Analytics**\n",
            "\n",
            "Utilize machine learning algorithms to analyze brain activity data from BCI systems, providing actionable insights into how learners absorb new information. This could enable educators to create more effective learning pathways and interventions, predicting which concepts may require more practice or review.\n",
            "\n",
            "**3. Neuro-adaptive Learning Paths**\n",
            "\n",
            "Design learning pathways that adapt to an individual's brain activity and cognitive abilities, optimizing the learning experience. This could involve instructors or AI-powered systems dynamically adjusting the pace, content, or difficulty level of the material based on real-time brain activity data.\n",
            "\n",
            "**4. Skills Augmentation for Professionals**\n",
            "\n",
            "Offer BCI-powered skills augmentation programs for professionals looking to enhance their technical skills, linguistic abilities, or cognitive proficiencies. Brain-computer interfaces could enable efficient learning and practice, accelerating the development of new skills.\n",
            "\n",
            "**5. Neuro-diversity Support**\n",
            "\n",
            "Leverage BCI technology to support learners with neuro-diverse conditions, such as ADHD, autism, or dyslexia. Brain-computer interfaces could help these individuals navigate complex learning environments more effectively, using tailored pathways and interventions to enhance their academic or professional pursuits.\n",
            "\n",
            "**6. Talent Identification and Development**\n",
            "\n",
            "Use BCI systems to identify and develop exceptional talent in various domains, such as sports, arts, or sciences. By analyzing brain activity, researchers could reveal novel capabilities or exceptional abilities in individuals, providing personalized training programs to accelerate their development.\n",
            "\n",
            "**7. Virtual Reality-based Learning**\n",
            "\n",
            "Combine BCI technology with virtual reality (VR) to create immersive learning experiences that stimulate cognitive development and engagement. Learners could interact with virtual environments and simulate real-world scenarios, using brain-computer interfaces to navigate and respond to virtual stimuli.\n",
            "\n",
            "**8. Personalized Career Guidance**\n",
            "\n",
            "Develop a system that analyzes brain activity data to match individuals with career paths that align with their cognitive abilities and interests. This could involve AI-powered career assessments, using BCI data to identify areas where individuals are most likely to excel and provide tailored guidance for career development.\n",
            "\n",
            "**9. Virtual Mentorship and Coaching**\n",
            "\n",
            "Offer virtual mentorship programs that leverage BCI technology to connect learners with experienced coaches and mentors. Brain-computer interfaces could facilitate real-time feedback and interaction, enabling participants to receive personalized guidance and support in a remote setting.\n",
            "\n",
            "**10. Innovation Incubators**\n",
            "\n",
            "Establish innovation incubators where entrepreneurs and researchers work together to develop new applications of BCI technology in talent development. These incubators could foster collaborative innovation, connecting experts from various fields to advance our understanding of the intersection between cognitive science, AI, and learning.\n",
            "\n",
            "\n",
            "**You: ** [type 'exit' to close chat]\n",
            "Chatbot: It seems like you meant to ask another question, but the text was cut off. Please rephrase or complete your question, and I'll be happy to help.\n",
            "\n",
            "\n",
            "**You: ** [type 'exit' to close chat]exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple Prompt below"
      ],
      "metadata": {
        "id": "37s64RDYBqMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_content_simple(prompt):\n",
        "  reponse = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant. \"},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return reponse.choices[0].message.content"
      ],
      "metadata": {
        "id": "8izTBX8SrjNq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_prompt = \"provide one use case for graph database technology in retail industry in less than 2 sentence\"\n",
        "prompt = input(\"\\nEnter the prompt to be provided to the model : \") or default_prompt\n",
        "print(\"Prompt : \",prompt)\n",
        "output = generate_content_simple(prompt)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akXKryFtUFlj",
        "outputId": "653ee6bc-5e56-4903-d5b9-40572b928ec2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the prompt to be provided to the model : llama 2 8b instruct model is large or small or micro\n",
            "Prompt :  llama 2 8b instruct model is large or small or micro\n",
            "The Hugging Face Llama model 2 8b is considered a large language model.\n",
            "\n",
            "The 2 in \"Llama 2\" refers to the generation of the model, while the 8b indicates the number of parameters, which is 8 billion.\n"
          ]
        }
      ]
    }
  ]
}