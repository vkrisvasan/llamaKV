{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLHIIECnN2UsLL9zfZwVOS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkrisvasan/llamaKV/blob/main/llamaindexYouTubeVideoCommentResponse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is designed to fetch comments from a YouTube video,\n",
        "#load the video's transcript, create a vector index from the transcript,\n",
        "#and then use a large language model to respond to the top comments.\n",
        "#create YOUTUBE_API_KEY in Google Developers Console >new project>Explore & Enable APIs.>\n",
        "#navigate to YouTube Data API v3 under YouTube APIs>Enable the API>\n",
        "#Create a credential>Note the API key\n",
        "\n",
        "# Install required packages\n",
        "!pip install llama-index llama-index-llms-groq groq llama-index-embeddings-huggingface llama-index-readers-youtube-transcript -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfDL0h6JC8FP",
        "outputId": "baaff46d-9bc2-4201-e6b3-6fcc95a6663b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.9/861.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from llama_index.llms.groq import Groq\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
        "from llama_index.core import (VectorStoreIndex, StorageContext, load_index_from_storage,Settings)\n"
      ],
      "metadata": {
        "id": "9pZbkFHuCpKI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import os and getpass for handling credentials\n",
        "import os\n",
        "import getpass\n",
        "# Prompt for credentials if not found in environment variables\n",
        "credential_names = [\"GROQ_API_KEY\",\"YOUTUBE_API_KEY\"]\n",
        "for credential in credential_names:\n",
        "  if credential not in os.environ:\n",
        "    os.environ[credential]=getpass.getpass(\"Provide your...\" + credential)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsoribsXCqUo",
        "outputId": "2d17ddf7-db58-41a0-84ef-026eec21c5b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide your...GROQ_API_KEY··········\n",
            "Provide your...YOUTUBE_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_ID = \"Kbk9BiPhm7o\"  # Replace with your actual video ID\n",
        "# Set up API key and video ID\n",
        "YOUTUBE_API_KEY = os.environ['YOUTUBE_API_KEY']\n",
        "\n",
        "# Step 1: Initialize the YouTube API client\n",
        "youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)"
      ],
      "metadata": {
        "id": "0Fx9thvECqco"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments(video_id, max_results=100):\n",
        "    comments = []\n",
        "    response = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        maxResults=max_results,\n",
        "        textFormat=\"plainText\"\n",
        "    ).execute()\n",
        "\n",
        "    for item in response.get('items', []):\n",
        "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "        comments.append(comment)\n",
        "\n",
        "    return comments"
      ],
      "metadata": {
        "id": "L2fGqqngCqlp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch comments from the video\n",
        "comments = get_comments(VIDEO_ID)\n",
        "print(f\"Fetched {len(comments)} comments\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5ZKYuR2CqvP",
        "outputId": "43f9dad7-a2be-416c-b09e-6dad82501395"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 100 comments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq Llama-8B model\n",
        "llm = Groq(model=\"llama-3.1-8b-instant\", api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "print(\"LLM initialized\")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "print(\"Embedding model initialized\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "#  Load YouTube Transcript\n",
        "youtube_link = f\"https://www.youtube.com/watch?v={VIDEO_ID}\"\n",
        "loader = YoutubeTranscriptReader()\n",
        "documents = loader.load_data(ytlinks=[youtube_link])\n",
        "print(\"Documents loaded\")\n",
        "\n",
        "# Create a Vector Index from the Transcript\n",
        "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
        "print(\"Index created\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv7dwjBtD3lQ",
        "outputId": "51add229-c6b0-4954-a0e4-2d6f04515e64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM initialized\n",
            "Embedding model initialized\n",
            "Documents loaded\n",
            "Index created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Persist the Index to Storage\n",
        "persist_dir = \"./youtube_index_storage\"\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "#index.storage_context = storage_context\n",
        "index.storage_context.persist(persist_dir=persist_dir)\n",
        "print(\"Index persisted\")\n",
        "\n",
        "# Load the Index from Storage\n",
        "storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
        "index = load_index_from_storage(storage_context=storage_context)\n",
        "print(\"Index loaded from storage\")\n",
        "\n",
        "# Create a Query Engine from the Index\n",
        "query_engine = index.as_query_engine(llm=llm)\n",
        "print(\"Query engine created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDwbvS2oEUjZ",
        "outputId": "d561224f-ca45-4c36-8ff8-8a3f38bbd57a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index persisted\n",
            "Index loaded from storage\n",
            "Query engine created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5BmkKykBCT8",
        "outputId": "d503b349-dcf5-4d1d-cbd3-8aba74325eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**YouTube Comment: 1:21:52 Musk claiming to be an alien is pure troll comment that an unreasonable amount of people will now believe\n",
            "\n",
            "**Langauge Model Response: It's interesting to consider how some statements can be perceived as having a significant impact on people's beliefs, even if they're not meant to be taken literally. The idea that a well-known figure might make a comment that seems outlandish, only to have some people take it seriously, raises questions about the nature of trust and the spread of information.\n",
            "\n",
            "**YouTube Comment: It's so much better of the camera didn't keep on panning to each subject. Both of you should be in the scene at the same time. Way better. And a tv in the middle.\n",
            "\n",
            "**Langauge Model Response: It would be more engaging to have a conversation with both participants in the same frame, allowing for a more dynamic and interactive discussion. A TV in the middle could also be a great way to display visual aids or demonstrations, making the conversation more engaging and easier to follow.\n",
            "\n",
            "**YouTube Comment: 4:56:40  - on death and the fear of “this consciousness ending”.  Do you ever consider if you will that consciousness , that light Lex speaks of , actually isn’t just extinguished at death? \n",
            "Take the Star Trek “transporter” thoughtexperiment. If one step into a transporter pad A and is “beamed” to Pad B , does that same person appear on pad B ? Or is it simply a facsimile of the person who was dematerialized on pad A , but with the copied memories and personality that make them who they are ? \n",
            " I posit to you that same event happens each time you “lose consciousness”  is it you who wakes up the next morning ?\n",
            "Will YOU, the person reading this comment actually awake tomorrow? Or is it simply the electrical storm inside you mind that forms your consciousness     Restarts , and YOU died the night when you lost consciousness. The new you will wake up , with all the memories of the days before.\n",
            "So when you feel that urge to stay up later , to fight sleep, it’s always been so strong because you knew perhaps preternaturally that you just wanted to live… a bit longer. \n",
            "I think we forget this over time , but as children we know it, bedtime truly may be as cruel as your kids make it out to be .\n",
            "\n",
            "**Langauge Model Response: The idea that consciousness might not be extinguished at death, but rather transformed or continued in some form, is a fascinating concept. It's a notion that challenges our conventional understanding of the relationship between consciousness and the physical body.\n",
            "\n",
            "The Star Trek transporter thought experiment is a great analogy for this idea. If we consider the transporter to be a device that scans and recreates a person's consciousness, rather than simply dematerializing and rematerializing their physical body, then it's possible to imagine that consciousness could be preserved in some way.\n",
            "\n",
            "This idea raises interesting questions about the nature of identity and self. If the person who wakes up the next morning is not the same physical entity that went to sleep, but rather a recreated or continued version of themselves, then what does it mean to be \"you\"? Is it the memories, experiences, and personality that make up your consciousness, or is it something more fundamental?\n",
            "\n",
            "This perspective also changes the way we think about death and the fear of losing consciousness. If consciousness is not extinguished, but rather transformed or continued, then the fear of death might be less about the loss of one's existence, and more about the unknown nature of what comes next.\n",
            "\n",
            "Ultimately, this is a deeply philosophical and existential question that may not have a definitive answer. However, it's a thought-provoking idea that challenges us to think more deeply about the nature of consciousness and our place in the world.\n",
            "\n",
            "**YouTube Comment: Doctor Octopus for president\n",
            "\n",
            "**Langauge Model Response: It seems like a humorous idea, but I'm not sure if Doctor Octopus would be a suitable candidate for the presidency. He's a fictional character known for his intelligence and mechanical abilities, but also for his villainous tendencies and lack of concern for human life. Perhaps we could consider a more benevolent and responsible leader for the role.\n",
            "\n",
            "**YouTube Comment: https://www.youtube.com/watch?v=vKQi3bBA1y8&pp=ygUKdGhlIG1hdHJpeA%3D%3D\n",
            "\n",
            "**Langauge Model Response: It seems like you're asking about a YouTube video. However, I don't see any information about the video you're asking about in the provided context. The context appears to be a transcript of a conversation between two individuals, possibly an interview, but it doesn't mention a specific video with the given URL.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Respond to the Selected Comments [exclude the 1st comment position as it is metadata about the video]\n",
        "top_comments = comments[27:32]  # Select comments based on position\n",
        "\n",
        "for comment in top_comments:\n",
        "    response = query_engine.query(comment)\n",
        "    print(f\"**YouTube Comment: {comment}\\n\")\n",
        "    print(f\"**Langauge Model Response: {response}\\n\")\n"
      ]
    }
  ]
}